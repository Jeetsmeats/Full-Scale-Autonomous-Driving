{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeetsmeats/Full-Scale-Autonomous-Driving/blob/main/Full_scale_Autonomous_Driving_Jeet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full-Scale Autonomous Driving: Simulations Based Comparison\n",
        "\n",
        "## Subject: AI4Robotics (ELEN90095)\n",
        "## Authors:\n",
        "- Yusuf Berdan GÃ¼zel (1051639)\n",
        "- Gunjeet Singh (1170248)"
      ],
      "metadata": {
        "id": "2VksEwjcIgfd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDosFab_5dXh"
      },
      "source": [
        "## Install Dependencies (Only on Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_N7W1TU5dXl",
        "outputId": "2993281b-b478-4ee0-ea33-099cf3e0f7c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: osqp in /usr/local/lib/python3.10/dist-packages (0.6.7.post3)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from osqp) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from osqp) (1.13.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp) (0.1.7.post4)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gymnasium stable_baselines3\n",
        "!pip install osqp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3yPimmT5dXn",
        "outputId": "0ffc6120-597d-4231-85fd-a82dec0baa6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai4r-gym'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 194 (delta 64), reused 27 (delta 10), pack-reused 64 (from 1)\u001b[K\n",
            "Receiving objects: 100% (194/194), 160.29 KiB | 342.00 KiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Cloning into 'Full-Scale-Autonomous-Driving'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 46 (delta 1), reused 11 (delta 1), pack-reused 35 (from 1)\u001b[K\n",
            "Receiving objects: 100% (46/46), 96.73 MiB | 15.03 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gitlab.unimelb.edu.au/ai4r/ai4r-gym.git\n",
        "!git clone https://github.com/Jeetsmeats/Full-Scale-Autonomous-Driving.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX2pNVFF5dXo",
        "outputId": "f19e77dd-bc3c-421f-d2bd-1d52b5fbb536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai4r-gym/ai4r-gym\n"
          ]
        }
      ],
      "source": [
        "%cd ai4r-gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GJSwiVG5dXo"
      },
      "source": [
        "## Library Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Zcl4DigK5dXo"
      },
      "outputs": [],
      "source": [
        "import ai4rgym\n",
        "from ai4rgym.envs.road import Road\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "from stable_baselines3 import PPO, SAC, DDPG\n",
        "from utils import ensure_dir, ensure_dirs, eval_model, evaluate_policy\n",
        "from utils import plot_rewards, plot_and_animate_trajectory\n",
        "from evaluation.evaluation_for_autonomous_driving import simulate_policy\n",
        "from evaluation.evaluation_for_autonomous_driving import plot_results_from_time_series_dict\n",
        "import matplotlib.pyplot as plt\n",
        "import osqp\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy import sparse, linalg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oodcAOp15dXp"
      },
      "source": [
        "## Environment Settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "GmkPGGI85dXp"
      },
      "outputs": [],
      "source": [
        "# SPECIFY THE VEHCILE PARAMETERS\n",
        "bicycle_model_parameters = {\n",
        "    \"Lf\" : 0.55*2.875,\n",
        "    \"Lr\" : 0.45*2.875,\n",
        "    \"m\"  : 2000.0,\n",
        "    \"Iz\" : (1.0/12.0) * 2000.0 * (4.692**2+1.850**2),\n",
        "    \"Cm\" : (1.0/100.0) * (1.0 * 400.0 * 9.0) / 0.2286,\n",
        "    \"Cd\" : 0.5 * 0.24 * 2.2204 * 1.202,\n",
        "    \"delta_offset\" : 0 * np.pi/180,\n",
        "    \"delta_request_max\" : 45 * np.pi/180,\n",
        "    \"Ddelta_lower_limit\" : -45 * np.pi/180,\n",
        "    \"Ddelta_upper_limit\" :  45 * np.pi/180,\n",
        "    \"v_transition_min\": 3.0,    # v_transition_min = 3.0 m/s\n",
        "    \"v_transition_max\": 5.0,    # v_transition_max = 5.0 m/s\n",
        "    \"body_len_f\" : (0.55*2.875) * 1.5,\n",
        "    \"body_len_r\" : (0.45*2.875) * 1.5,\n",
        "    \"body_width\" : 2.50,\n",
        "}\n",
        "\n",
        "# SPECIFY THE ROAD\n",
        "\n",
        "# This road will not be used for training / evaluation\n",
        "# this is just kept in place to initialize the environment\n",
        "road_elements_list = [\n",
        "    {\"type\":\"straight\", \"length\":100.0},\n",
        "    {\"type\":\"curved\", \"curvature\":1/800.0, \"angle_in_degrees\":15.0},\n",
        "    {\"type\":\"straight\", \"length\":100.0},\n",
        "    {\"type\":\"curved\", \"curvature\":-1/400.0, \"angle_in_degrees\":30.0},\n",
        "    {\"type\":\"straight\", \"length\":100.0},\n",
        "]\n",
        "\n",
        "# SPECIFY THE NUMERICAL INTEGRATION DETAILS\n",
        "numerical_integration_parameters = {\n",
        "    \"method\" : \"rk4\",\n",
        "    \"Ts\" : 0.05,\n",
        "    \"num_steps_per_Ts\" : 1,\n",
        "}\n",
        "\n",
        "# SPECIFY THE INITIAL STATE DISTRIBUTION\n",
        "\n",
        "py_init_min = -1.0\n",
        "py_init_max =  1.0\n",
        "\n",
        "v_init_min_in_kmh = 30.0\n",
        "v_init_max_in_kmh = 40.0\n",
        "\n",
        "py_init_min = -1.0\n",
        "py_init_max =  1.0\n",
        "\n",
        "initial_state_bounds = {\n",
        "    \"px_init_min\" : 0.0,\n",
        "    \"px_init_max\" : 0.0,\n",
        "    \"py_init_min\" : py_init_min,\n",
        "    \"py_init_max\" : py_init_max,\n",
        "    \"theta_init_min\" : 0.0,\n",
        "    \"theta_init_max\" : 0.0,\n",
        "    \"vx_init_min\" : v_init_min_in_kmh * (1.0/3.6),\n",
        "    \"vx_init_max\" : v_init_max_in_kmh * (1.0/3.6),\n",
        "    \"vy_init_min\" : 0.0,\n",
        "    \"vy_init_max\" : 0.0,\n",
        "    \"omega_init_min\" : 0.0,\n",
        "    \"omega_init_max\" : 0.0,\n",
        "    \"delta_init_min\" : 0.0,\n",
        "    \"delta_init_max\" : 0.0,\n",
        "}\n",
        "\n",
        "# SPECIFY THE TERMINATION PARAMETERS\n",
        "termination_parameters = {\n",
        "    \"speed_lower_bound\"  :  0.0,\n",
        "    \"speed_upper_bound\"  :  (200.0/3.6),\n",
        "    \"distance_to_closest_point_upper_bound\"  :  20.0,\n",
        "    \"reward_speed_lower_bound\"  :  0.0,\n",
        "    \"reward_speed_upper_bound\"  :  0.0,\n",
        "    \"reward_distance_to_closest_point_upper_bound\"  :  0.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rent1DP65dXr"
      },
      "source": [
        "## Setting Observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "4vqaFOLs5dXr"
      },
      "outputs": [],
      "source": [
        "# SPECIFY THE OBSERVATION PARAMETERS\n",
        "observation_parameters = {\n",
        "    \"should_include_ground_truth_px\"                       :  \"info\",\n",
        "    \"should_include_ground_truth_py\"                       :  \"info\",\n",
        "    \"should_include_ground_truth_theta\"                    :  \"info\",\n",
        "    \"should_include_ground_truth_vx\"                       :  \"info\",\n",
        "    \"should_include_ground_truth_vy\"                       :  \"info\",\n",
        "    \"should_include_ground_truth_omega\"                    :  \"info\",\n",
        "    \"should_include_ground_truth_delta\"                    :  \"info\",\n",
        "    \"should_include_road_progress_at_closest_point\"        :  \"obs\",\n",
        "    \"should_include_vx_sensor\"                             :  \"obs\",\n",
        "    \"should_include_distance_to_closest_point\"             :  \"obs\",\n",
        "    \"should_include_heading_angle_relative_to_line\"        :  \"obs\",\n",
        "    \"should_include_heading_angular_rate_gyro\"             :  \"obs\",\n",
        "    \"should_include_closest_point_coords_in_body_frame\"    :  \"info\",\n",
        "    \"should_include_look_ahead_line_coords_in_body_frame\"  :  \"info\",\n",
        "    \"should_include_road_curvature_at_closest_point\"       :  \"obs\",\n",
        "    \"should_include_look_ahead_road_curvatures\"            :  \"info\",\n",
        "    \"scaling_for_ground_truth_px\"                       :  1.0,\n",
        "    \"scaling_for_ground_truth_py\"                       :  1.0,\n",
        "    \"scaling_for_ground_truth_theta\"                    :  1.0,\n",
        "    \"scaling_for_ground_truth_vx\"                       :  1.0,\n",
        "    \"scaling_for_ground_truth_vy\"                       :  1.0,\n",
        "    \"scaling_for_ground_truth_omega\"                    :  1.0,\n",
        "    \"scaling_for_ground_truth_delta\"                    :  1.0,\n",
        "    \"scaling_for_road_progress_at_closest_point\"        :  1.0,\n",
        "    \"scaling_for_vx_sensor\"                             :  1.0,\n",
        "    \"scaling_for_distance_to_closest_point\"             :  1.0,\n",
        "    \"scaling_for_heading_angle_relative_to_line\"        :  1.0,\n",
        "    \"scaling_for_heading_angular_rate_gyro\"             :  1.0,\n",
        "    \"scaling_for_closest_point_coords_in_body_frame\"    :  1.0,\n",
        "    \"scaling_for_look_ahead_line_coords_in_body_frame\"  :  1.0,\n",
        "    \"scaling_for_road_curvature_at_closest_point\"       :  1.0,\n",
        "    \"scaling_for_look_ahead_road_curvatures\"            :  1.0,\n",
        "\n",
        "    \"vx_sensor_bias\"    : 0.0,\n",
        "    \"vx_sensor_stddev\"  : 0.1,\n",
        "\n",
        "    \"distance_to_closest_point_bias\"    :  0.0,\n",
        "    \"distance_to_closest_point_stddev\"  :  0.01,\n",
        "\n",
        "    \"heading_angle_relative_to_line_bias\"    :  0.0,\n",
        "    \"heading_angle_relative_to_line_stddev\"  :  0.01,\n",
        "\n",
        "    \"heading_angular_rate_gyro_bias\"    :  0.0,\n",
        "    \"heading_angular_rate_gyro_stddev\"  :  0.01,\n",
        "\n",
        "    \"closest_point_coords_in_body_frame_bias\"    :  0.0,\n",
        "    \"closest_point_coords_in_body_frame_stddev\"  :  0.0,\n",
        "\n",
        "    \"look_ahead_line_coords_in_body_frame_bias\"    :  0.0,\n",
        "    \"look_ahead_line_coords_in_body_frame_stddev\"  :  0.0,\n",
        "\n",
        "    \"road_curvature_at_closest_point_bias\"    :  0.0,\n",
        "    \"road_curvature_at_closest_point_stddev\"  :  0.0,\n",
        "\n",
        "    \"look_ahead_road_curvatures_bias\"    :  0.0,\n",
        "    \"look_ahead_road_curvatures_stddev\"  :  0.0,\n",
        "\n",
        "    \"look_ahead_line_coords_in_body_frame_distance\"    :  100.0,\n",
        "    \"look_ahead_line_coords_in_body_frame_num_points\"  :  10,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeqIgZDf5dXs"
      },
      "source": [
        "## Environment Creation:\n",
        "- Generate a new environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lkG0ROGv5dXs"
      },
      "outputs": [],
      "source": [
        "def create_env(road_randomization_params=None, road_elements_list=None):\n",
        "    # If road_elements_list is provided, use it directly\n",
        "    if road_elements_list is not None:\n",
        "        road_elements = road_elements_list\n",
        "    else:\n",
        "        # Generate random road elements based on randomization parameters\n",
        "        domain_randomizer = DomainRandomizationWrapper(None, road_randomization_params)\n",
        "        road_elements = domain_randomizer.generate_random_road_elements_list()\n",
        "\n",
        "    env = gym.make(\n",
        "        \"ai4rgym/autonomous_driving_env\",\n",
        "        render_mode=None,\n",
        "        bicycle_model_parameters=bicycle_model_parameters,\n",
        "        road_elements_list=road_elements,\n",
        "        numerical_integration_parameters=numerical_integration_parameters,\n",
        "        termination_parameters=termination_parameters,\n",
        "        initial_state_bounds=initial_state_bounds,\n",
        "        observation_parameters=observation_parameters,\n",
        "    )\n",
        "\n",
        "    # Set the integration method and time step\n",
        "    Ts_sim = 0.05\n",
        "    integration_method = \"rk4\"\n",
        "    env.unwrapped.set_integration_method(integration_method)\n",
        "    env.unwrapped.set_integration_Ts(Ts_sim)\n",
        "\n",
        "    # Set the road condition\n",
        "    env.unwrapped.set_road_condition(road_condition=\"wet\")\n",
        "\n",
        "    # Rescale actions and wrap the environment\n",
        "    env = gym.wrappers.RescaleAction(env, min_action=-1, max_action=1)\n",
        "\n",
        "    # If using domain randomization, wrap the environment\n",
        "    if road_randomization_params is not None:\n",
        "        env = DomainRandomizationWrapper(env, road_randomization_params)\n",
        "\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RTI-MPC Policy\n",
        "\n",
        "- Real-time Iteration Model Predictive Control Policy\n",
        "- Included system dynamics and state-space model.\n",
        "- Model failed to solve."
      ],
      "metadata": {
        "id": "4udW43KfGSIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RTIMPC:\n",
        "\n",
        "    def __init__(self, bicycle_model_parameters, Q, R,\n",
        "                 s_initial, s_lower, s_upper, Ts, Nsim, state_ref, env):\n",
        "\n",
        "        # State and action dimensions\n",
        "        self.n_s = 4\n",
        "        self.n_a = 2\n",
        "\n",
        "        # Initial State\n",
        "        self.s_initial = s_initial\n",
        "\n",
        "        # Number of simulation points\n",
        "        self.Nsim = Nsim\n",
        "\n",
        "        # Define Model Parameters\n",
        "        self.bicycle_model_parameters = bicycle_model_parameters\n",
        "        self.Ts = Ts                  # Sampling Period\n",
        "\n",
        "        # Prediction/Control Horizon\n",
        "        self.N = 20\n",
        "\n",
        "        # Sampling Frequency\n",
        "        self.Ts = 0.05\n",
        "\n",
        "        # Quadratic programmer\n",
        "        self.qp = osqp.OSQP()\n",
        "\n",
        "        # Cost Matrices\n",
        "        self.Q = sparse.diags(Q, format=\"csc\", dtype=np.float32)\n",
        "        self.R = sparse.diags(R, format=\"csc\", dtype=np.float32)\n",
        "\n",
        "        # Define constraints\n",
        "        self.s_lower = np.array(s_lower)\n",
        "        self.s_upper = np.array(s_upper)\n",
        "        self.a_lower = np.array([[-100], [np.deg2rad(-45)]])\n",
        "        self.a_upper = np.array([[100], [np.deg2rad(45)]])\n",
        "\n",
        "        # Model Parameters\n",
        "        self.Cd = self.bicycle_model_parameters[\"Cd\"]\n",
        "        self.Cm = self.bicycle_model_parameters[\"Cm\"]\n",
        "        self.Lf = self.bicycle_model_parameters[\"Lf\"]\n",
        "        self.Lr = self.bicycle_model_parameters[\"Lr\"]\n",
        "        self.m = self.bicycle_model_parameters[\"m\"]\n",
        "\n",
        "        # State reference value\n",
        "        self.p_ref = state_ref[0]\n",
        "        self.d_ref = state_ref[1]\n",
        "        self.mu_ref = state_ref[2]\n",
        "        self.v_ref =  state_ref[3]\n",
        "\n",
        "        # Lower and upper bounds of box constraints\n",
        "        self.sa_lower = np.vstack([ self.s_lower , self.a_lower ])\n",
        "        self.sa_upper = np.vstack([ self.s_upper , self.a_upper ])\n",
        "        self.x_lower = np.vstack([ np.kron(np.ones((self.N,1),dtype=np.float32), self.sa_lower), self.s_lower ])\n",
        "        self.x_upper = np.vstack([ np.kron(np.ones((self.N,1),dtype=np.float32), self.sa_upper), self.s_upper ])\n",
        "\n",
        "        # Pre-allocate matrices for storing the results\n",
        "        self.state_trajectory = np.empty((self.n_s, self.Nsim + 1), dtype=np.float32)\n",
        "        self.action_trajectory = np.empty((self.n_s, self.Nsim), dtype=np.float32)\n",
        "\n",
        "        # Set the initial condition in the first column\n",
        "        self.state_trajectory[:, 0] = [\n",
        "            self.s_initial[0].item() - self.p_ref.item(),\n",
        "            self.s_initial[0].item() - self.d_ref.item(),\n",
        "            self.s_initial[0].item() - self.mu_ref.item(),\n",
        "            self.s_initial[0].item() - self.v_ref.item()\n",
        "        ]\n",
        "\n",
        "        # Set the initial state as the current state\n",
        "        self.s_current = self.s_initial\n",
        "        self.i = 1\n",
        "\n",
        "        # Define the environment\n",
        "        self.env = env\n",
        "\n",
        "    def compute_action(self, observation, info_dict, terminated, truncated):\n",
        "\n",
        "      a_current = np.zeros((1, 2))\n",
        "\n",
        "      if self.i != 1:\n",
        "\n",
        "        # Current State measurements\n",
        "        p = observation[\"road_progress_at_closest_point\"][0]\n",
        "        d = observation[\"distance_to_closest_point\"][0]\n",
        "        mu = observation[\"heading_angle_relative_to_line\"][0]\n",
        "        v = observation[\"vx_sensor\"][0]\n",
        "\n",
        "        self.s_current = [p - self.p_ref, d - self.d_ref, mu - self.mu_ref, v - self.v_ref]\n",
        "\n",
        "      curvature = observation[\"road_curvature_at_closest_point\"][0]\n",
        "\n",
        "      x_eq = [0, 0, 0, self.v_ref]\n",
        "      u_eq = [0, 0]\n",
        "\n",
        "      # Get the curvature\n",
        "      kappa = self.env.unwrapped.road.convert_progression_to_curvature(np.array([curvature]))\n",
        "\n",
        "      # Discrete-time matrices\n",
        "      A, B, Aeq, Beq = self.discrete_time_dynamics(x_eq, u_eq, kappa)\n",
        "      A_for_osqp = sparse.vstack([ Aeq , sparse.eye(self.N*(self.n_s+self.n_a)+self.n_s,format=\"csc\")],format=\"csc\")\n",
        "      l_for_osqp = np.vstack([ Beq , self.x_lower ])\n",
        "      u_for_osqp = np.vstack([ Beq , self.x_upper ])\n",
        "\n",
        "      # DARE Solution\n",
        "      P = self.solve_discrete_are(A, B, self.Q, self.R)\n",
        "\n",
        "      # Objective function matrix\n",
        "      QR = sparse.block_diag([self.Q, self.R])\n",
        "      H = sparse.block_diag([ sparse.kron(sparse.eye(self.N,format=\"csc\"), QR), P],format=\"csc\")\n",
        "\n",
        "      # Set up the QP solver for each time step.\n",
        "      self.qp.setup(P=2*H,\n",
        "        q=np.zeros(H.shape[1]),\n",
        "        A=A_for_osqp,\n",
        "        l=l_for_osqp,\n",
        "        u=u_for_osqp,\n",
        "        verbose=False,\n",
        "      )\n",
        "\n",
        "      # Update the constraint vector with the current state\n",
        "      l_for_osqp[0:self.n_s] = self.s_current\n",
        "      u_for_osqp[0:self.n_s] = self.s_current\n",
        "\n",
        "      # Update the OSQP object with the current state\n",
        "      self.qp.update(l=l_for_osqp, u=u_for_osqp)\n",
        "\n",
        "      res = self.qp.solve()\n",
        "\n",
        "      if res.info.status != 'solved':\n",
        "        raise ValueError('QSQP did not solve the problem')\n",
        "\n",
        "      # Update the constraint vector with the current state\n",
        "      l_for_osqp[0:self.n_s] = self.s_current\n",
        "      u_for_osqp[0:self.n_s] = self.s_current\n",
        "\n",
        "      # Update the OSQP object with the current state\n",
        "      self.qp.update(l=l_for_osqp, u=u_for_osqp)\n",
        "\n",
        "      # Solve the optimization program\n",
        "      osqp_result = self.qp.solve()\n",
        "\n",
        "      # Extract the status string\n",
        "      osqp_status_string = osqp_result.info.status\n",
        "\n",
        "      # Display the status if it is anything other than success\n",
        "      if (osqp_status_string != \"solved\"):\n",
        "        raise ValueError(\"OSQP did not solve the problem, returned status = \" + osqp_status_string)\n",
        "\n",
        "      # Extract the optimal solution\n",
        "      x_optimal = osqp_result.x\n",
        "\n",
        "      # Extract the first action from the optimal solution\n",
        "      a_current[:][0] = x_optimal[self.n_s: (self.n_s + self.n_a)]\n",
        "\n",
        "      # Compute the next state\n",
        "      s_next = A @ self.s_current + B @ a_current\n",
        "\n",
        "      # Store the results\n",
        "      self.state_trajectory[:][self.i+1] = s_next[:,0]\n",
        "      self.action_trajectory[:][self.i] = a_current[:,0]\n",
        "      # self.x_optimal_trajectory[:][self.i] = x_optimal\n",
        "      # self.solver_run_times[self.i] = osqp_result.info.run_time\n",
        "      # self.solve_status_val[self.i] = osqp_result.info.status_val\n",
        "\n",
        "      # Iterate the current state\n",
        "      self.s_current = s_next\n",
        "      self.i += 1\n",
        "\n",
        "      F_action = a_current[0, 0]\n",
        "      steer_action = a_current[1, 0]\n",
        "\n",
        "      # Return the actions as a numpy array\n",
        "      return np.array([F_action, steer_action], dtype=np.float32)\n",
        "\n",
        "    def solve_discrete_are(self, A, B, Q, R):\n",
        "      \"\"\"\n",
        "      Solve the discrete Ricatti Equation.\n",
        "      \"\"\"\n",
        "      # Riccati solution\n",
        "      P_dense = linalg.solve_discrete_are(A.toarray(),B.toarray(),Q.toarray(),R.toarray())\n",
        "\n",
        "      # Convert P to be in sparse format\n",
        "      P = sparse.csc_matrix(P_dense, shape=(self.n_s, self.n_s), dtype=np.float32)\n",
        "\n",
        "      # DARE Solution\n",
        "      return P\n",
        "\n",
        "    def discrete_time_dynamics(self, x_eq, u_eq, kappa):\n",
        "      \"\"\"\n",
        "      Derive discrete time dynamics\n",
        "      \"\"\"\n",
        "      # Set Equilibrium Points\n",
        "      p_eq = x_eq[0]\n",
        "      d_eq = x_eq[1]\n",
        "      mu_eq = x_eq[2]\n",
        "      v_eq = x_eq[3]\n",
        "\n",
        "      # Action Equilibrium Points\n",
        "      F_eq = u_eq[0]\n",
        "      steer_eq = u_eq[1]\n",
        "\n",
        "      # State Dynamics\n",
        "      A12 = -(kappa * v_eq * np.cos(mu_eq)) / (np.power((1 + d_eq * kappa), 2))\n",
        "      A13 = -(v_eq * np.sin(mu_eq)) / (1 + d_eq * kappa)\n",
        "      A14 = (np.cos(mu_eq)) / (1 + d_eq * kappa)\n",
        "\n",
        "      A23 = v_eq * np.cos(mu_eq)\n",
        "      A24 = np.sin(mu_eq)\n",
        "\n",
        "      A32 = ((kappa ** 2) * v_eq * np.cos(mu_eq)) / (np.power((1 + d_eq * kappa), 2))\n",
        "      A33 = (kappa * v_eq * np.sin(mu_eq)) / (1 + d_eq * kappa)\n",
        "      A34 = ((np.tan(steer_eq)) / (self.Lr)) - ((kappa * np.cos(mu_eq)) / (1 + d_eq * kappa))\n",
        "\n",
        "      A44 = (2 / self.m) * self.Cd * v_eq * np.sign(v_eq)\n",
        "\n",
        "      A12 = A12.item()\n",
        "      A13 = A13.item()\n",
        "      A14 = A14.item()\n",
        "      A23 = A23.item()\n",
        "      A24 = A24.item()\n",
        "      A32 = A32.item()\n",
        "      A33 = A33.item()\n",
        "      A34 = A34.item()\n",
        "      A44 = A44.item()\n",
        "\n",
        "      # Input Dynamics\n",
        "      B32 = (v_eq / self.Lr) * (1 / np.power(np.cos(steer_eq), 2))\n",
        "      B41 = (self.Cm / self.m) * v_eq * np.sign(v_eq)\n",
        "\n",
        "      B32 = B32.item()\n",
        "      B41 = B41.item()\n",
        "\n",
        "      # Continuous State-Space\n",
        "      Ac = np.array([\n",
        "      [ 0.,  A12, A13, A14],\n",
        "      [ 0., 0., A23, A24],\n",
        "      [ 0., A32, A33, A34],\n",
        "      [ 0., 0., 0., A44]\n",
        "      ], dtype=np.float32)\n",
        "\n",
        "      Bc = np.array([\n",
        "      [ 0., 0.],\n",
        "      [ 0., 0.],\n",
        "      [ 0., B32],\n",
        "      [ B41, 0.]\n",
        "      ], dtype=np.float32)\n",
        "\n",
        "      # Compute the discrete time dynamics matrices\n",
        "      # > Stack the matrices\n",
        "      Mc = np.vstack([ np.hstack([Ac,Bc]) , np.zeros((self.n_a,self.n_s+self.n_a),\n",
        "      dtype=np.float32) ])\n",
        "\n",
        "      # Matrix Exponential\n",
        "      Md = linalg.expm( Mc * self.Ts )\n",
        "\n",
        "      # Discrete-time State Space\n",
        "      Ad = Md[0:self.n_s,0:self.n_s]\n",
        "      Bd = Md[0:self.n_s,self.n_s:(self.n_s+self.n_a)]\n",
        "\n",
        "      # Convert Ad and Bd to be in sparse format\n",
        "      A = sparse.csc_matrix(Ad, shape=(self.n_s,self.n_s), dtype=np.float32)\n",
        "      B = sparse.csc_matrix(Bd, shape=(self.n_s,self.n_a), dtype=np.float32)\n",
        "\n",
        "      # Matrix for all time steps of the dynamics\n",
        "      AB = sparse.hstack([A,B])\n",
        "\n",
        "      negI_zero_block = sparse.hstack([ -sparse.eye(self.n_s,format=\"csc\"), sparse.csc_matrix((self.n_s,self.n_a)) ])\n",
        "      zero_negI_col = sparse.vstack([sparse.csc_matrix(((self.N-1)*self.n_s,self.n_s)), -sparse.eye(self.n_s,format=\"csc\")])\n",
        "      ABI_stacked = \\\n",
        "        sparse.hstack([ sparse.kron(sparse.eye(self.N,format=\"csc\") , AB) ,\n",
        "      sparse.csc_matrix((self.N*self.n_s,self.n_s)) ]) \\\n",
        "        + \\\n",
        "        sparse.hstack([ sparse.kron(sparse.eye(self.N,k=1,format=\"csc\"),negI_zero_block) ,\n",
        "      zero_negI_col ])\n",
        "\n",
        "      # Matrix for selecting the first state\n",
        "      s0_selector = sparse.hstack([ sparse.eye(self.n_s,format=\"csc\"), sparse.csc_matrix((self.n_s,self.N*(self.n_s+self.n_a)))])\n",
        "\n",
        "      # Stacking the above two together\n",
        "      Aeq = sparse.vstack([ s0_selector , ABI_stacked ])\n",
        "      Beq = np.vstack([ self.s_initial , np.zeros((self.N * self.n_s,1)) ])\n",
        "      return A, B, Aeq, Beq"
      ],
      "metadata": {
        "id": "fb41UE2XGcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Policy Implementation\n"
      ],
      "metadata": {
        "id": "tswsDsi-qX52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "class BaselinePolicyRewardWrapper(gym.RewardWrapper):\n",
        "\n",
        "    def __init__(self, env):\n",
        "        super(BaselinePolicyRewardWrapper, self).__init__(env)\n",
        "\n",
        "        # Performance metric initialisation\n",
        "        self.total_distance = 0\n",
        "        self.total_speed = 0\n",
        "        self.min_speed = 0\n",
        "        self.max_speed = 0\n",
        "        self.time_above_vlimit = 0\n",
        "        self.time_above_dlimit = 0\n",
        "        self.n_speed_violations = 0\n",
        "        self.n_distance_violations = 0\n",
        "        self.total_steer = 0\n",
        "        self.total_ang_velocity = 0\n",
        "        self.duration_of_speed_limit = []\n",
        "        self.duration_of_distance_limit = []\n",
        "\n",
        "        self.curr_time_over_dlimit = 0\n",
        "        self.curr_time_over_tlimit = 0\n",
        "\n",
        "        self.distance_flag = False\n",
        "        self.speed_flag = False\n",
        "\n",
        "        self.max_dist = 0\n",
        "\n",
        "        self.vmax = 30.0 / 3.6\n",
        "        self.Ts = 0.05\n",
        "\n",
        "        self.N = 1\n",
        "\n",
        "        self.omega_prev = 0\n",
        "        self.progress = 0\n",
        "\n",
        "        self.velocities = np.array([])\n",
        "\n",
        "    def get_performance(self):\n",
        "        avg_speed = self.total_speed / self.N\n",
        "        avg_distance = self.total_distance / self.N\n",
        "        avg_steer = self.total_steer / self.N\n",
        "        avg_ang_velocity = self.total_ang_velocity / self.N\n",
        "\n",
        "        min_speed = self.min_speed\n",
        "        max_speed = self.max_speed\n",
        "        max_distance = self.max_dist\n",
        "        time_above_vlimit = self.time_above_vlimit\n",
        "        time_above_dlimit = self.time_above_dlimit\n",
        "        n_speed_violations = self.n_speed_violations\n",
        "        n_distance_violations = self.n_distance_violations\n",
        "\n",
        "        avg_speed_violation_time = np.mean(self.duration_of_speed_limit)\n",
        "        avg_distance_violation_time = np.mean(self.duration_of_distance_limit)\n",
        "\n",
        "        std_speed = np.std(self.velocities)\n",
        "\n",
        "        return {\n",
        "            \"avg_speed\": avg_speed,\n",
        "            \"avg_distance\": avg_distance,\n",
        "            \"avg_steer\": avg_steer,\n",
        "            \"avg_ang_velocity\": avg_ang_velocity,\n",
        "            \"min_speed\": min_speed,\n",
        "            \"max_speed\": max_speed,\n",
        "            \"max_distance\": max_distance,\n",
        "            \"time_above_vlimit\": time_above_vlimit,\n",
        "            \"time_above_dlimit\": time_above_dlimit,\n",
        "            \"n_speed_violations\": n_speed_violations,\n",
        "            \"n_distance_violations\": n_distance_violations,\n",
        "            \"avg_speed_violation_time\": avg_speed_violation_time,\n",
        "            \"avg_distance_violation_time\": avg_distance_violation_time,\n",
        "            \"std_speed\": std_speed\n",
        "        }\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        RL Policy time step.\n",
        "        \"\"\"\n",
        "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "        steer_angle = action[1]\n",
        "\n",
        "        # Observations\n",
        "        distance_to_line = abs(observation[\"distance_to_closest_point\"][0])\n",
        "        vx = observation[\"vx_sensor\"][0]\n",
        "        theta = observation[\"heading_angle_relative_to_line\"][0]\n",
        "        omega = observation[\"heading_angular_rate_gyro\"][0]\n",
        "        progress = observation[\"road_progress_at_closest_point\"][0]\n",
        "\n",
        "       # Calculate angular acceleration\n",
        "        alpha = (omega - self.omega_prev) / self.Ts\n",
        "        omega_prev = omega\n",
        "\n",
        "        if distance_to_line < 1 and abs(theta) < np.pi / 3:\n",
        "          reward += 0.15\n",
        "        else:\n",
        "          reward -= 0.1\n",
        "\n",
        "        if vx >= (20.0 / 3.6) and vx <= (60.0 / 3.6):\n",
        "          reward += 0.5\n",
        "\n",
        "        if vx < (20.0 / 3.6) and vx > (80.0 / 3.6):\n",
        "          reward -= 0.2\n",
        "\n",
        "        if omega < 0.5:\n",
        "          reward += 0.5\n",
        "\n",
        "        if progress + 3 > self.progress:\n",
        "          reward += 0.5\n",
        "\n",
        "        self.progress = progress\n",
        "\n",
        "        self.performance_metrics(distance_to_line, vx, theta, omega, progress, steer_angle)\n",
        "        self.N += 1\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def performance_metrics(self, distance_to_line, vx, theta, omega, progress, steer):\n",
        "        self.total_distance += distance_to_line\n",
        "        self.min_speed = min(self.min_speed, vx)\n",
        "        self.max_speed = max(self.max_speed, vx)\n",
        "\n",
        "        self.max_dist = max(self.max_dist, distance_to_line)\n",
        "\n",
        "        if vx > self.vmax and not self.speed_flag:\n",
        "            self.speed_flag = True\n",
        "            self.n_speed_violations += 1\n",
        "        elif vx <= self.vmax and self.speed_flag:\n",
        "            self.speed_flag = False\n",
        "            self.duration_of_speed_limit.append(self.curr_time_over_tlimit)\n",
        "            self.curr_time_over_tlimit = 0\n",
        "\n",
        "        if distance_to_line > 1 and not self.speed_flag:\n",
        "            self.time_above_dlimit += self.Ts\n",
        "            self.n_distance_violations += 1\n",
        "        elif distance_to_line <= 1 and self.distance_flag:\n",
        "            self.distance_flag = False\n",
        "            self.duration_of_distance_limit.append(self.curr_time_over_dlimit)\n",
        "            self.curr_time_over_dlimit = 0\n",
        "\n",
        "        if self.speed_flag:\n",
        "          self.time_above_vlimit += self.Ts\n",
        "          self.curr_time_over_tlimit += self.Ts\n",
        "\n",
        "        if self.distance_flag:\n",
        "          self.time_above_dlimit += self.Ts\n",
        "          self.curr_time_over_dlimit += self.Ts\n",
        "\n",
        "        self.total_steer += abs(steer)\n",
        "        self.total_ang_velocity += abs(omega)\n",
        "\n",
        "        self.total_speed += abs(vx)\n",
        "\n",
        "        self.velocities = np.array(vx)\n"
      ],
      "metadata": {
        "id": "UBWCnyAk-2hW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg-kKNzO5dXt"
      },
      "source": [
        "## Domain Randomization Wrapper:\n",
        "- Designate a domain randomization wrapper for random generation of the terrain in training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "cK81Mgiz5dXt"
      },
      "outputs": [],
      "source": [
        "class DomainRandomizationWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, road_randomization_params=None):\n",
        "        super(DomainRandomizationWrapper, self).__init__(env)\n",
        "        self.road_randomization_params = road_randomization_params\n",
        "\n",
        "    def generate_random_road_elements_list(self):\n",
        "        params = self.road_randomization_params or {}\n",
        "        num_elements_range = params.get('num_elements_range', (2, 5))\n",
        "        straight_length_range = params.get('straight_length_range', (50.0, 200.0))\n",
        "        curvature_range = params.get('curvature_range', (-1/500.0, 1/500.0))\n",
        "        angle_range = params.get('angle_range', (10.0, 60.0))\n",
        "\n",
        "        road_elements = []\n",
        "        num_elements = random.randint(*num_elements_range)\n",
        "\n",
        "        for _ in range(num_elements):\n",
        "            element_type = random.choice(['straight', 'curved'])\n",
        "            if element_type == 'straight':\n",
        "                length = random.uniform(*straight_length_range)\n",
        "                road_elements.append({\"type\": \"straight\", \"length\": length})\n",
        "            else:\n",
        "                curvature = random.uniform(*curvature_range)\n",
        "                angle = random.uniform(*angle_range)\n",
        "                road_elements.append({\n",
        "                    \"type\": \"curved\",\n",
        "                    \"curvature\": curvature,\n",
        "                    \"angle_in_degrees\": angle\n",
        "                })\n",
        "        return road_elements\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        # Generate a new random road\n",
        "        road_elements_list = self.generate_random_road_elements_list()\n",
        "        self.env.unwrapped.road_elements_list = road_elements_list\n",
        "        self.env.unwrapped.road = Road(epsilon_c=(1/10000), road_elements_list=road_elements_list)\n",
        "        self.env.unwrapped.total_road_length = self.env.unwrapped.road.get_total_length()\n",
        "        self.env.unwrapped.total_road_length_for_termination = max(\n",
        "            self.env.unwrapped.total_road_length - 0.1,\n",
        "            0.9999 * self.env.unwrapped.total_road_length\n",
        "        )\n",
        "        # Call the original reset method\n",
        "        return self.env.reset(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RL8tJMk5dXt"
      },
      "source": [
        "### Visualizing Random Roads:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlqslvpT5dXu"
      },
      "source": [
        "## Setting up Training/Evaluation Environments:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ------------- MAKE CHANGES TO THE ROAD RANDOMIZATION PARAMS HERE ------- ###\n",
        "# Difficulty levels for curriculum learning\n",
        "road_randomization_params_levels = {\n",
        "    1: {\n",
        "        'num_elements_range': (4, 8),\n",
        "        'straight_length_range': (150.0, 300.0),\n",
        "        'curvature_range': (-1/1000.0, 1/1000.0),\n",
        "        'angle_range': (5.0, 15.0),\n",
        "    },\n",
        "    2: {\n",
        "        'num_elements_range': (5, 10),\n",
        "        'straight_length_range': (100.0, 200.0),\n",
        "        'curvature_range': (-1/800.0, 1/800.0),\n",
        "        'angle_range': (10.0, 30.0),\n",
        "    },\n",
        "    3: {\n",
        "        'num_elements_range': (10, 12),\n",
        "        'straight_length_range': (80.0, 150.0),\n",
        "        'curvature_range': (-1/500.0, 1/500.0),\n",
        "        'angle_range': (20.0, 45.0),\n",
        "    },\n",
        "    4: {\n",
        "        'num_elements_range': (12, 17),\n",
        "        'straight_length_range': (60.0, 120.0),\n",
        "        'curvature_range': (-1/300.0, 1/300.0),\n",
        "        'angle_range': (30.0, 60.0),\n",
        "    },\n",
        "    5: {\n",
        "        'num_elements_range': (16,18),\n",
        "        'straight_length_range': (50.0, 100.0),\n",
        "        'curvature_range': (-1/200.0, 1/200.0),\n",
        "        'angle_range': (45.0, 90.0),\n",
        "    },\n",
        "    6: {\n",
        "        'num_elements_range': (18, 20),             # More road elements\n",
        "        'straight_length_range': (50.0, 100.0),   # Shorter straight segments\n",
        "        'curvature_range': (-1/100.0, 1/100.0),   # Tighter curves\n",
        "        'angle_range': (30.0, 70.0)               # More aggressive curves with wider angle range\n",
        "    }}"
      ],
      "metadata": {
        "id": "JOBScBhy__f2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a fixed, difficult road for evaluation\n",
        "road_elements_list_difficult = [\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": 1/300.0, \"angle_in_degrees\": 90.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": -1/200.0, \"angle_in_degrees\": 120.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": 1/300.0, \"angle_in_degrees\": 90.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": -1/200.0, \"angle_in_degrees\": 120.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": 1/300.0, \"angle_in_degrees\": 90.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": -1/200.0, \"angle_in_degrees\": 120.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": 1/300.0, \"angle_in_degrees\": 90.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "    {\"type\": \"curved\", \"curvature\": -1/200.0, \"angle_in_degrees\": 120.0},\n",
        "    {\"type\": \"straight\", \"length\": 50.0},\n",
        "]\n",
        "\n",
        "# Create the evaluation environment with the fixed difficult road\n",
        "eval_env = create_env(None, road_elements_list_difficult)\n",
        "\n",
        "# Render the road\n",
        "eval_env.render_matplotlib_init_figure()\n",
        "eval_env.render_matplotlib_plot_road()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "M7gJz_mHSw-B",
        "outputId": "72c85ada-a303-4bf2-af5f-1b15ec3db617"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.render_matplotlib_init_figure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.render_matplotlib_init_figure` for environment variables or `env.get_wrapper_attr('render_matplotlib_init_figure')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.render_matplotlib_plot_road to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.render_matplotlib_plot_road` for environment variables or `env.get_wrapper_attr('render_matplotlib_plot_road')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the RTI-MPC Policy\n"
      ],
      "metadata": {
        "id": "ldotx_MgT4pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training environment for this level\n",
        "train_env_mpc = create_env(road_randomization_params=road_randomization_params_levels[6])\n",
        "train_env_mpc = DomainRandomizationWrapper(train_env_mpc, road_randomization_params=road_randomization_params_levels[6])\n",
        "\n",
        "# Specify the policy name as a string\n",
        "policy_name = \"mpc\"\n",
        "\n",
        "# Create the directories where the figures are saved\n",
        "mpc_figs = f\"models/mpc/eval\"\n",
        "\n",
        "logdir = \"logs\"\n",
        "file_name_suffix = \"example\"\n",
        "\n",
        "# Create directory\n",
        "ensure_dir(mpc_figs)\n",
        "\n",
        "Nsim = 5000\n",
        "Q = np.array([0., 100., 10., 5])       # 4x1 column vector\n",
        "R = np.array([1., 1.])                 # 2x1 column vector\n",
        "\n",
        "s_lower = np.array([[0.], [-5.], [np.deg2rad(2)], [80 / 3.6]])  # 4x1 column vector\n",
        "s_upper = np.array([[np.inf], [5.], [np.deg2rad(2)], [120 / 3.6]])  # 4x1 column vector\n",
        "state_ref = np.array([[0.], [0.], [0.], [100 / 3.6]])           # 4x1 column vector\n",
        "\n",
        "# Initialize from environment observations\n",
        "obs, info = train_env_mpc.reset()\n",
        "p_init = obs[\"road_progress_at_closest_point\"][0]\n",
        "d_init = obs[\"distance_to_closest_point\"][0]\n",
        "mu_init = obs[\"heading_angle_relative_to_line\"][0]\n",
        "v_init = obs[\"vx_sensor\"][0]\n",
        "\n",
        "s_initial = np.array([[p_init], [d_init], [mu_init], [v_init]])  # 4x1 column vector\n",
        "sim_seed = 69\n",
        "\n",
        "mpc = RTIMPC(bicycle_model_parameters, Q, R,\n",
        "                 s_initial, s_lower, s_upper, 0.05,\n",
        "              Nsim, state_ref, train_env_mpc)\n",
        "\n",
        "sim_time_series_dict = simulate_policy(train_env_mpc, Nsim, mpc, seed=sim_seed, verbose=1)\n",
        "plot_details_list = plot_results_from_time_series_dict(train_env_mpc, sim_time_series_dict, mpc_figs, file_name_suffix, should_plot_reward=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "teVZIcs_PFMu",
        "outputId": "9f779c91-df09-415f-a8ae-aaeae22723ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Now starting simulation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "QSQP did not solve the problem",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-d9821142e79e>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m               Nsim, state_ref, train_env_mpc)\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0msim_time_series_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_env_mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNsim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mplot_details_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_results_from_time_series_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_env_mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_time_series_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_figs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_plot_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ai4r-gym/evaluation/evaluation_for_autonomous_driving.py\u001b[0m in \u001b[0;36msimulate_policy\u001b[0;34m(env, N_sim, policy, seed, should_save_look_ahead_results, should_save_observations, verbose)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Compute the action to apply at this time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_terminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_truncated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Step forward the gymnasium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# > This also updates the \"current_ground_truth\" dictionary within the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b3548776387d>\u001b[0m in \u001b[0;36mcompute_action\u001b[0;34m(self, observation, info_dict, terminated, truncated)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'solved'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QSQP did not solve the problem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0;31m# Update the constraint vector with the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: QSQP did not solve the problem"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKv3poDd5dXv"
      },
      "source": [
        "## Model Definition and Training (SAC Policy):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "xrzFGEiQ5dXv",
        "outputId": "3f366d6e-b032-4f06-8278-7264fac60948"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'stable_baselines3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ec67cfe1249>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# import math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"baseline_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTIMESTEPS_PER_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from stable_baselines3 import SAC\n",
        "# import math\n",
        "model_name = \"baseline_model\"\n",
        "\n",
        "TIMESTEPS_PER_EPOCH = 10000\n",
        "TOTAL_EPOCHS = 32\n",
        "\n",
        "logdir = \"logs\"\n",
        "models_dir = f\"models/{model_name}\"\n",
        "figs_dir_train = f\"models/{model_name}/figs_train\"\n",
        "figs_dir_test = f\"models/{model_name}/figs_test\"\n",
        "\n",
        "ensure_dirs([logdir, models_dir, figs_dir_train, figs_dir_test])\n",
        "\n",
        "# Calculate epochs per level\n",
        "levels = sorted(road_randomization_params_levels.keys())\n",
        "EPOCHS_PER_LEVEL = TOTAL_EPOCHS // len(levels)\n",
        "\n",
        "current_epoch = 0\n",
        "\n",
        "# Start training loop over difficulty levels\n",
        "for idx, level in enumerate(levels):\n",
        "    print(f\"Training on difficulty level {level}\")\n",
        "    road_randomization_params = road_randomization_params_levels[level]\n",
        "\n",
        "    # Create the training environment for this level\n",
        "    train_env = create_env(road_randomization_params=road_randomization_params)\n",
        "    train_env = DomainRandomizationWrapper(train_env, road_randomization_params = road_randomization_params)\n",
        "    train_env = BaselinePolicyRewardWrapper(train_env)\n",
        "\n",
        "    if idx == 0:\n",
        "\n",
        "      sac_params = {\n",
        "            \"learning_rate\": 3e-4,\n",
        "            \"buffer_size\": int(1e6),    # Replay buffer size\n",
        "            \"batch_size\": 4096,         # Batch size\n",
        "            \"gamma\": 0.98,              # Discount factor\n",
        "            \"tau\": 0.005,               # Polyak averaging for target networks\n",
        "            \"target_entropy\": \"auto\",   # Automatic entropy tuning\n",
        "            \"train_freq\": 1,            # Train every step\n",
        "            \"gradient_steps\": 1,        # Gradient steps per training step\n",
        "        }\n",
        "\n",
        "      # Define RL model\n",
        "      baseline_model = SAC(\"MultiInputPolicy\", train_env,\n",
        "              **sac_params,\n",
        "              verbose = 1,\n",
        "              tensorboard_log=logdir)\n",
        "      # For subsequent levels, set the new environment\n",
        "      baseline_model.set_env(train_env)\n",
        "\n",
        "    for epoch in range(1, EPOCHS_PER_LEVEL + 1):\n",
        "        current_epoch += 1\n",
        "        print(f\"Epoch {current_epoch}/{TOTAL_EPOCHS} at difficulty level {level}\")\n",
        "\n",
        "        baseline_model.learn(\n",
        "            total_timesteps=TIMESTEPS_PER_EPOCH,\n",
        "            reset_num_timesteps=False,\n",
        "            tb_log_name=f\"{model_name}\"\n",
        "        )\n",
        "        baseline_model.save(f\"{models_dir}/{TIMESTEPS_PER_EPOCH * (current_epoch)}\")\n",
        "\n",
        "        # Evaluate on the most recent training road\n",
        "        eval_model(train_env, baseline_model, figs_dir_train, TIMESTEPS_PER_EPOCH * current_epoch, max_steps=50000)\n",
        "\n",
        "    # Close the training environment before moving to the next level\n",
        "    train_env.close()\n",
        "\n",
        "# Evaluate on evaluation road\n",
        "eval_model(eval_env, baseline_model, figs_dir_test, TIMESTEPS_PER_EPOCH * current_epoch, max_steps=50000)\n",
        "\n",
        "# After training, save the final model\n",
        "baseline_model.save(f\"{models_dir}/final_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model Figures"
      ],
      "metadata": {
        "id": "aS24DinBS7NX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWuXezgt5dXx"
      },
      "outputs": [],
      "source": [
        "model_name = \"PPO_dr_long\"\n",
        "model_idx = 950000\n",
        "\n",
        "path_for_saving_figures = f\"models/{model_name}/eval\"\n",
        "ensure_dir(path_for_saving_figures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg3ijXbq5dXx"
      },
      "source": [
        "### Put the RL model into a policy class with a 'standardize' interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBLsDu7O5dXx"
      },
      "outputs": [],
      "source": [
        "from policies.rl_policy import RLPolicy\n",
        "\n",
        "# Put the RL model into a policy class\n",
        "rl_policy = RLPolicy(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4uQMFil5dXx"
      },
      "source": [
        "### Perform One simulation of the policy, plot the time series results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k801LKQB5dXy"
      },
      "outputs": [],
      "source": [
        "# Import the function for simulating the autonomous driving environment\n",
        "from evaluation.evaluation_for_autonomous_driving import simulate_policy\n",
        "from evaluation.evaluation_for_autonomous_driving import plot_results_from_time_series_dict\n",
        "\n",
        "# Specify the length of the simulation in time steps\n",
        "N_sim = 5000\n",
        "\n",
        "# Specify the seed for when the simulate function resets the random number generator\n",
        "sim_seed = 1;\n",
        "\n",
        "# Call the function for simulating a given RL model\n",
        "sim_time_series_dict = simulate_policy(eval_env, N_sim, rl_policy, seed=sim_seed, verbose=1)\n",
        "\n",
        "# Call the plotting function\n",
        "file_name_suffix = \"example\"\n",
        "plot_details_list = plot_results_from_time_series_dict(eval_env, sim_time_series_dict, path_for_saving_figures, file_name_suffix, should_plot_reward=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYPoArlD5dXy"
      },
      "source": [
        "### Animate the time series results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REFJ7Z4i5dXz"
      },
      "outputs": [],
      "source": [
        "def animate_from_sim_time_series_dict(sim_time_series_dict, Ts, path_for_saving_figures):\n",
        "    # Extract the necessary trajectory information from the \"sim_time_series_dict\"\n",
        "    px_traj    = sim_time_series_dict[\"px\"]\n",
        "    py_traj    = sim_time_series_dict[\"py\"]\n",
        "    theta_traj = sim_time_series_dict[\"theta\"]\n",
        "    delta_traj = sim_time_series_dict[\"delta\"]\n",
        "    # Call the environments function to create the simulation\n",
        "    ani = eval_env.unwrapped.render_matplotlib_animation_of_trajectory(px_traj, py_traj, theta_traj, delta_traj, Ts, traj_increment=3)\n",
        "    # Save the animation\n",
        "    ani.save(f\"{path_for_saving_figures}/trajectory_animation.gif\")\n",
        "    print(f'Saved animation at {path_for_saving_figures}/trajectory_animation.gif')\n",
        "    # Return the animation object\n",
        "    return ani"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E30EwT8x5dXz"
      },
      "outputs": [],
      "source": [
        "# Call the animation functoin\n",
        "ani = animate_from_sim_time_series_dict(sim_time_series_dict, numerical_integration_parameters[\"Ts\"], path_for_saving_figures)\n",
        "# Display the animation\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRjxApzo5dX0"
      },
      "source": [
        "### Define a performance Metrics Function per simulation time series:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W0WARAk5dX0"
      },
      "outputs": [],
      "source": [
        "def compute_performance_metrics_from_time_series(sim_time_series_dict):\n",
        "    # Compute the statistics of the distance to the line\n",
        "    abs_dist_to_line_time_series = np.abs(sim_time_series_dict[\"distance_to_closest_point\"])\n",
        "    avg_dist  = np.nanmean(abs_dist_to_line_time_series)\n",
        "    std_dist  = np.nanstd(abs_dist_to_line_time_series)\n",
        "    max_dist  = np.nanmax(abs_dist_to_line_time_series)\n",
        "\n",
        "    # Compute the statistics of the speed in the forward direction (i.e., the body-frame x-axis direction)\n",
        "    speed_time_series = np.abs(sim_time_series_dict[\"vx\"])\n",
        "    avg_speed = np.nanmean(speed_time_series)\n",
        "    std_speed = np.nanstd(speed_time_series)\n",
        "    max_speed = np.nanmax(speed_time_series)\n",
        "    min_speed = np.nanmin(speed_time_series)\n",
        "\n",
        "    # Return the results\n",
        "    return {\n",
        "        \"avg_dist\"   :  avg_dist,\n",
        "        \"std_dist\"   :  std_dist,\n",
        "        \"max_dist\"   :  max_dist,\n",
        "        \"avg_speed\"  :  avg_speed * 3.6,\n",
        "        \"std_speed\"  :  std_speed * 3.6,\n",
        "        \"max_speed\"  :  max_speed * 3.6,\n",
        "        \"min_speed\"  :  min_speed * 3.6,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "805EOM0h5dX0"
      },
      "source": [
        "### Run the Performance Metric Function for one simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA-grx-Q5dX1"
      },
      "outputs": [],
      "source": [
        "# Simulate with the same seed as above to check that it gets the results consistent\n",
        "sim_seed = 1;\n",
        "sim_time_series_dict = simulate_policy(eval_env, N_sim, rl_policy, seed=sim_seed, verbose=1)\n",
        "\n",
        "# Call the function for computing the performance metrics\n",
        "pm_dict = compute_performance_metrics_from_time_series(sim_time_series_dict)\n",
        "\n",
        "# Display the performance metric values\n",
        "print(\"Performance Metric dictionary:\")\n",
        "print(pm_dict)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}